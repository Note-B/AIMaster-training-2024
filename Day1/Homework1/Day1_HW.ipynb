{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":32658,"status":"ok","timestamp":1717067213617,"user":{"displayName":"Eakkaphob B.","userId":"02931425301555833011"},"user_tz":-420},"id":"9i9HzFrNlyDh","outputId":"dbef56be-5189-446a-92e9-ef607f97d5e8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Notebook cleaned.\n"]}],"source":["import IPython\n","import sys\n","import os\n","\n","import openai\n","\n","\n","def clean_notebook():\n","    IPython.display.clear_output(wait=True)\n","    print(\"Notebook cleaned.\")\n","\n","!pip install openai\n","!pip install gradio\n","\n","# Clean up the notebook\n","clean_notebook()"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":2326,"status":"ok","timestamp":1717067222057,"user":{"displayName":"Eakkaphob B.","userId":"02931425301555833011"},"user_tz":-420},"id":"hVjAATdIF4oq"},"outputs":[],"source":["\n","openai.api_key = \"sk-proj-sQO0S1mGBrbhcgO2bGpDT3BlbkFJpOG6rn9OfMM1SLdq14yO\"\n","\n","os.environ['HF_TOKEN'] =\"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\"\n","hf_token               = os.environ['HF_TOKEN']\n"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6542,"status":"ok","timestamp":1717067611301,"user":{"displayName":"Eakkaphob B.","userId":"02931425301555833011"},"user_tz":-420},"id":"F0Bgt-BSIMgu","outputId":"831fabde-d975-4f93-ee76-ecb86538165e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Not running in Google Colab\n"]}],"source":["# Add information from text file\n","if 'google.colab' in sys.modules:\n","  from google.colab import drive\n","  drive.mount('/content/drive')\n","\n","  with open(\"/content/drive/My Drive/Colab Notebooks/MasterAI KMITL Training/hdd_history.txt\", 'r') as f:\n","    hdd_history = f.read()\n","\n","  drive.flush_and_unmount()\n","  \n","else:\n","  print(\"Not running in Google Colab\")\n","  with open(\"./hdd_history.txt\", 'r', errors=\"ignore\") as f:\n","    hdd_history = f.read()\n","\n","#IPython.display.Markdown(hdd_history)\n","\n","# Define system expertise\n","system_prompt = \"\"\"You are a technology blogger whos has more than 15 years \\\n","experience working in IT company. Your answers should be \\\n","short, concise, and clear. If you don't know the answer, say Sorry, I can't \\\n","find a good answer for you.\n","\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","from transformers import AutoModelForCausalLM,AutoTokenizer,BitsAndBytesConfig\n","import torch\n","\n","################################################################################\n","# bitsandbytes parameters\n","################################################################################\n","\n","# Activate 4-bit precision base model loading\n","use_4bit = True\n","\n","# Compute dtype for 4-bit base models\n","bnb_4bit_compute_dtype = \"float16\"\n","\n","# Quantization type (fp4 or nf4)\n","bnb_4bit_quant_type = \"nf4\"\n","\n","# Activate nested quantization for 4-bit base models (double quantization)\n","use_nested_quant = False\n","\n","\n","# Load tokenizer and model with QLoRA configuration\n","compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=use_4bit,\n","    bnb_4bit_quant_type=bnb_4bit_quant_type,\n","    bnb_4bit_compute_dtype=compute_dtype,\n","    bnb_4bit_use_double_quant=use_nested_quant,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Typhoon\n","\n","def generate_Typhoon_Llama(model_id, user_prompt, temperature, max_token=256, top_p=0.9):\n","\n","    model     = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config,device_map=\"auto\",token=hf_token)\n","    tokenizer = AutoTokenizer.from_pretrained(model_id) \n","    \n","    messages = [\n","        {\"role\": \"system\", \"content\": system_prompt},\n","        {\"role\": \"user\", \"content\": user_prompt},\n","    ]\n","\n","    input_ids = tokenizer.apply_chat_template(messages,add_generation_prompt=True,return_tensors=\"pt\").to(model.device)\n","\n","    terminators = [\n","        tokenizer.eos_token_id,\n","        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n","    ]\n","\n","    outputs = model.generate(\n","        input_ids,\n","        max_new_tokens=max_token,\n","        pad_token_id=model.config.eos_token_id, \n","        eos_token_id=terminators,\n","        do_sample=True,\n","        temperature=temperature,\n","        top_p=top_p,\n","    )\n","\n","    response = outputs[0][input_ids.shape[-1]:]\n","    return tokenizer.decode(response, skip_special_tokens=True)"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":291,"status":"ok","timestamp":1717068111088,"user":{"displayName":"Eakkaphob B.","userId":"02931425301555833011"},"user_tz":-420},"id":"9QIWQip9GS9w"},"outputs":[],"source":["# Open AI\n","def generate_OpenAI(user_prompt, temperature, max_token=256):\n","    completion = openai.chat.completions.create(\n","        model='gpt-3.5-turbo',\n","        messages=[\n","            {\"role\": \"system\", \"content\": system_prompt},\n","            {\"role\": \"user\", \"content\": user_prompt},\n","        ],\n","        temperature=temperature,\n","        max_tokens=max_token,\n","    )\n","    return completion.choices[0].message.content"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1717068404547,"user":{"displayName":"Eakkaphob B.","userId":"02931425301555833011"},"user_tz":-420},"id":"_jc2y03mGW3y"},"outputs":[],"source":["def answer(question, temperature, max_token, model_list):\n","  context = hdd_history\n","  prompt = f\"\"\"Please answer the following question:\n","\n","  Question:\n","\n","  ```{question}```\n","\n","  Use the following context to find the answer:\n","\n","  ```{context}```\n","  \"\"\"\n","  #print(prompt)\n","  \n","  result1 = result2 = result3 = \"Not Available\"\n","  \n","  if \"OpenAI\" in model_list:\n","    result1 = generate_OpenAI(prompt, temperature, max_token)\n","  \n","  if \"Typhoon\" in model_list:\n","    model_use = \"scb10x/llama-3-typhoon-v1.5-8b-instruct\"\n","    result2 = generate_Typhoon_Llama(model_use, prompt, temperature, max_token)  \n","  \n","  if \"Llama\" in model_list:\n","    model_use = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n","    result3 = generate_Typhoon_Llama(model_use, prompt, temperature, max_token)  \n","    \n","  result = [result1, result2, result3]    \n","  return result "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":591},"executionInfo":{"elapsed":1350,"status":"ok","timestamp":1717068417496,"user":{"displayName":"Eakkaphob B.","userId":"02931425301555833011"},"user_tz":-420},"id":"VymTQYShNu-e","outputId":"635a34bb-26ff-4441-e12e-093200911934"},"outputs":[{"name":"stdout","output_type":"stream","text":["Running on local URL:  http://127.0.0.1:7867\n","Running on public URL: https://c2694958a9fef7263d.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"]},{"data":{"text/html":["<div><iframe src=\"https://c2694958a9fef7263d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":[]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["import gradio as gr\n","\n","# Example prompts\n","examples = [\n","    [\"What is the hard disk?\"],\n","    [\"How many HDD brands in the market\"],\n","    [\"What is the history of HDD?\"]\n","]\n","\n","# Create Gradio interface\n","interface = gr.Interface(\n","    fn=answer,\n","    inputs=[\n","        gr.Textbox(lines=2, placeholder=\"Enter your prompt here...\"),\n","        gr.Slider(minimum=0.1, maximum=1.0, step=0.1, value=0.85, label=\"Temperature\"),\n","        gr.Slider(minimum=0.1, maximum=256, step=1, value=256, label=\"token\"),\n","        gr.CheckboxGroup([\"OpenAI\", \"Typhoon\", \"Llama\"], label=\"Model selections\")\n","    ],\n","    outputs=[gr.Textbox(label=\"OpenAI result\"),gr.Textbox(label=\"Typhoon result\"),gr.Textbox(label=\"Llama result\")],\n","    title=\"Q&A for Hard Disk Drive Technology\",\n","    description=\"Enter any question about Hard Drive\",\n","    examples=examples\n",")\n","\n","# Launch the interface\n","interface.launch(share=True)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPWnPf0Kv/wEZ/EJmJAEz4w","mount_file_id":"1IeFo-6vdDzFw-kjoyzwY9Ntku-OU5-aj","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
